[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
srun: error: ouga14: tasks 0-3,5: Exited with exit code 1
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = agent.run()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = agent.run()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = agent.run()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    result = self._invoke_run(role)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    result = self._invoke_run(role)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._initialize_workers(self._worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = self._invoke_run(role)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._initialize_workers(self._worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._initialize_workers(self._worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._initialize_workers(self._worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._rendezvous(worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    self._rendezvous(worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._rendezvous(worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    self._rendezvous(worker_group)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    result = f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to listen on [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240306_143920-gnc21hpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ⭐️ View project at https://wandb.ai/luluh/singlesamplednam2
wandb: 🚀 View run at https://wandb.ai/luluh/singlesamplednam2/runs/gnc21hpj
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1020, in forward
    encoder_outputs = self.encoder(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 610, in forward
    layer_outputs = layer_module(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 495, in forward
    self_attention_outputs = self.attention(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 425, in forward
    self_outputs = self.self(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 284, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.039 MB uploaded (0.000 MB deduped)wandb: | 0.039 MB of 0.039 MB uploaded (0.000 MB deduped)wandb: 🚀 View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/gnc21hpj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240306_143920-gnc21hpj/logs
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3090983) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-06_14:39:46
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3090983)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ouga14: task 4: Exited with exit code 1
