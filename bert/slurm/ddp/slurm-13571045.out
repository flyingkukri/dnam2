You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type m2_bert to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: luluhu (luluh). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-chnz3hmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/chnz3hmy
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-yf7p4jxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/yf7p4jxg
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-n6s6epky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/n6s6epky
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-qo6bnvj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/qo6bnvj7
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-hl66z6wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/hl66z6wh
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/wandb/run-20240310_122113-3bhrym5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fullset_bs1024_6gpu_monarchhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/luluh/singlesamplednam2
wandb: üöÄ View run at https://wandb.ai/luluh/singlesamplednam2/runs/3bhrym5t
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/100000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
Traceback (most recent call last):
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/data/ceph/hdd/project/node_09/semi_supervised_multispecies/monarch/dnam2/bert/slurm/ddp/train.py", line 81, in <module>
    trainer.train()
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1013, in forward
    embedding_output = self.embeddings(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1013, in forward
    embedding_output = self.embeddings(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 238, in forward
    embeddings = self.dropout(embeddings)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 238, in forward
    embeddings = self.dropout(embeddings)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 1927, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2699, in training_step
    loss = self.compute_loss(model, inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/trainer.py", line 2731, in compute_loss
    outputs = model(**inputs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1020, in forward
    encoder_outputs = self.encoder(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1020, in forward
    encoder_outputs = self.encoder(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 610, in forward
    layer_outputs = layer_module(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 610, in forward
    layer_outputs = layer_module(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 495, in forward
    self_attention_outputs = self.attention(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 495, in forward
    self_attention_outputs = self.attention(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1020, in forward
    encoder_outputs = self.encoder(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 425, in forward
    self_outputs = self.self(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 425, in forward
    self_outputs = self.self(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 610, in forward
    layer_outputs = layer_module(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 284, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 284, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 495, in forward
    self_attention_outputs = self.attention(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 425, in forward
    self_outputs = self.self(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1358, in forward
    outputs = self.bert(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 284, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 1020, in forward
    encoder_outputs = self.encoder(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 610, in forward
    layer_outputs = layer_module(
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 495, in forward
    self_attention_outputs = self.attention(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 425, in forward
    self_outputs = self.self(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py", line 284, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.039 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/chnz3hmy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-chnz3hmy/logs
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.039 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/n6s6epky
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-n6s6epky/logs
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/hl66z6wh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-hl66z6wh/logs
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/yf7p4jxg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-yf7p4jxg/logs
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/3bhrym5t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-3bhrym5t/logs
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: üöÄ View run fullset_bs1024_6gpu_monarchhf at: https://wandb.ai/luluh/singlesamplednam2/runs/qo6bnvj7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240310_122113-qo6bnvj7/logs
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206198) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:30
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206198)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ouga14: task 5: Exited with exit code 1
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206196) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:35
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206196)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206194) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:35
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206194)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206212) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:35
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206212)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ouga14: task 0: Exited with exit code 1
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206211) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:36
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206211)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ouga14: tasks 3-4: Exited with exit code 1
srun: error: ouga14: task 2: Exited with exit code 1
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 206202) of binary: /opt/modules/i12g/anaconda/envs/m2-mixer/bin/python3.9
Traceback (most recent call last):
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/modules/i12g/anaconda/envs/m2-mixer/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-10_12:21:41
  host      : ouga14.cmm.in.tum.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 206202)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ouga14: task 1: Exited with exit code 1
