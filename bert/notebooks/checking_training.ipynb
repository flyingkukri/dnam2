{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc31059b-b8ea-4377-b026-a8dcd9d899d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import FlashFFTConv!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/.conda/envs/m2_bert/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000ba\n",
      "Using Monarch Mixer for Sequence Mixing: True\n",
      "-- Bidirectional: True\n",
      "-- Using Long Conv Residual: True\n",
      "-- Hyena w: 10\n",
      "-- Hyena w mod: 1\n",
      "-- Hyena filter order: 128\n",
      "-- Hyena filter dropout: 0.2\n",
      "-- Hyena filter wd: 0.1\n",
      "-- Hyena filter emb dim: 5\n",
      "-- Hyena filter lr: 0.001\n",
      "-- Hyena filter lr pos emb: 1e-05\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf as om\n",
    "from omegaconf import DictConfig\n",
    "from typing import cast\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "#from main import build_model\n",
    "import src.create_bert as bert_module\n",
    "import src.create_model as model_module\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "yaml_path = \"../yamls/pretrain/embed_dna_monarch-mixer-pretrain-786dim-80m-parameters.yaml\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gagneurlab/SpeciesLM\", revision=\"downstream_species_lm\")\n",
    "\n",
    "\n",
    "with open(yaml_path) as f:\n",
    "    cfg = om.load(f)\n",
    "cfg = cast(DictConfig, cfg)\n",
    "print(cfg.max_duration)\n",
    "model = model_module.create_model(cfg.model.get(\"model_config\"))\n",
    "#model = bert_module.create_bert_mlm(model_config = cfg.model.get(\"model_config\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a102cb-a33c-4161-9c0c-9ec78c2dc957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(5504, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (species_embeddings): Embedding(4096, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): MonarchMixerSequenceMixing(\n",
       "            (filter_fn): HyenaFilter(\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (pos_emb): PositionalEmbedding()\n",
       "              (implicit_filter): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                (1): Sin()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (3): Sin()\n",
       "                (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (5): Sin()\n",
       "                (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "              )\n",
       "              (implicit_filter_rev): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                (1): Sin()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (3): Sin()\n",
       "                (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (5): Sin()\n",
       "                (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "              )\n",
       "              (modulation): ExponentialModulation()\n",
       "            )\n",
       "            (filter_fn2): HyenaFilter(\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "              (pos_emb): PositionalEmbedding()\n",
       "              (implicit_filter): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                (1): Sin()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (3): Sin()\n",
       "                (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (5): Sin()\n",
       "                (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "              )\n",
       "              (implicit_filter_rev): Sequential(\n",
       "                (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "                (1): Sin()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (3): Sin()\n",
       "                (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (5): Sin()\n",
       "                (6): Linear(in_features=128, out_features=768, bias=False)\n",
       "              )\n",
       "              (modulation): ExponentialModulation()\n",
       "            )\n",
       "            (in_linear): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (short_filter): Conv1d(2304, 2304, kernel_size=(3,), stride=(1,), padding=(2,), groups=2304)\n",
       "          )\n",
       "          (mlp): BertGatedLinearUnitMLP(\n",
       "            (gated_layers): BlockdiagLinear()\n",
       "            (act): GELU(approximate='none')\n",
       "            (wo): BlockdiagLinear()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=5504, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07000c23-78e1-46f3-9abd-0aa0868366dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=singlesamplednam2\n",
      "torch.Size([1, 298])\n",
      "torch.Size([1, 300])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from collate import DataCollatorForLanguageModelingSpan\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Load model directly\n",
    "%env WANDB_PROJECT=singlesamplednam2\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_from_disk(\"../batch_species\")\n",
    "dataset = dataset.remove_columns([\"species_name\", \"__index_level_0__\"])\n",
    "\n",
    "data_collator = DataCollatorForLanguageModelingSpan(tokenizer, mlm=True, mlm_probability = 0.02, span_length = 6)\n",
    "\n",
    "dataloader = DataLoader(dataset[\"train\"], batch_size=1, collate_fn=data_collator)\n",
    "\n",
    "sample = next(iter(dataloader))\n",
    "#training_args = TrainingArguments(\n",
    "#    output_dir=\"./results/correct_model_1sample\",\n",
    "#    \n",
    "#    max_steps=100000,\n",
    "#    \n",
    "#    seed=17,\n",
    "#    per_device_train_batch_size=1,\n",
    "#    gradient_accumulation_steps=1,\n",
    "#    \n",
    "#    logging_strategy=\"steps\",\n",
    "#    logging_steps=1,\n",
    "#    \n",
    "#    remove_unused_columns=False,\n",
    "#    evaluation_strategy=\"no\",\n",
    "#    \n",
    "#    #dataloader_num_workers=0,\n",
    "#    run_name=\"repo_model_1sample\",\n",
    "#    report_to=\"wandb\"\n",
    "#)\n",
    "#\n",
    "#trainer = Trainer(\n",
    "#    model=model,\n",
    "#    args=training_args,\n",
    "#    train_dataset=dataset[\"train\"],\n",
    "#    eval_dataset=dataset[\"test\"],\n",
    "#    data_collator=data_collator\n",
    "#)\n",
    "#\n",
    "#\n",
    "##trainer.train()\n",
    "#tokenizer.vocab_size\n",
    "\n",
    "print(sample['species_id'].shape)\n",
    "print(sample['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca37baf-7eac-4137-8678-40b49f476ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=tensor(8.7274, grad_fn=<NllLossBackward0>), logits=tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3781c242-6fab-4a36-be34-7bb7834cd0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertForMaskedLM.forward() got an unexpected keyword argument 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs\n\u001b[1;32m      7\u001b[0m     }\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BertForMaskedLM.forward() got an unexpected keyword argument 'args'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(dataset[\"train\"], batch_size=1, shuffle=True, collate_fn=data_collator)\n",
    "for step, inputs in enumerate(train_dataloader):\n",
    "    inputs = {\n",
    "        \"args\": inputs\n",
    "    }\n",
    "    model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514ea4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ab3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ed89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9374a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
