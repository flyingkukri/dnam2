{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species_name': 'botrytis_porri_gca_004786265',\n",
       " '__index_level_0__': 1077855,\n",
       " 'input_ids': [2,\n",
       "  4203,\n",
       "  1030,\n",
       "  12,\n",
       "  33,\n",
       "  120,\n",
       "  466,\n",
       "  1850,\n",
       "  3292,\n",
       "  865,\n",
       "  3445,\n",
       "  1478,\n",
       "  1804,\n",
       "  3108,\n",
       "  129,\n",
       "  502,\n",
       "  1994,\n",
       "  3868,\n",
       "  3169,\n",
       "  373,\n",
       "  1477,\n",
       "  1797,\n",
       "  3078,\n",
       "  9,\n",
       "  22,\n",
       "  74,\n",
       "  281,\n",
       "  1112,\n",
       "  337,\n",
       "  1334,\n",
       "  1226,\n",
       "  794,\n",
       "  3161,\n",
       "  343,\n",
       "  1357,\n",
       "  1317,\n",
       "  1160,\n",
       "  531,\n",
       "  2112,\n",
       "  242,\n",
       "  953,\n",
       "  3798,\n",
       "  2889,\n",
       "  3349,\n",
       "  1096,\n",
       "  276,\n",
       "  1089,\n",
       "  246,\n",
       "  971,\n",
       "  3870,\n",
       "  3179,\n",
       "  416,\n",
       "  1650,\n",
       "  2492,\n",
       "  1761,\n",
       "  2934,\n",
       "  3531,\n",
       "  1823,\n",
       "  3182,\n",
       "  426,\n",
       "  1691,\n",
       "  2654,\n",
       "  2411,\n",
       "  1438,\n",
       "  1642,\n",
       "  2458,\n",
       "  1626,\n",
       "  2394,\n",
       "  1370,\n",
       "  1371,\n",
       "  1375,\n",
       "  1390,\n",
       "  1450,\n",
       "  1691,\n",
       "  2655,\n",
       "  2414,\n",
       "  1451,\n",
       "  1694,\n",
       "  2666,\n",
       "  2459,\n",
       "  1630,\n",
       "  2410,\n",
       "  1434,\n",
       "  1627,\n",
       "  2398,\n",
       "  1386,\n",
       "  1434,\n",
       "  1626,\n",
       "  2395,\n",
       "  1374,\n",
       "  1388,\n",
       "  1444,\n",
       "  1668,\n",
       "  2561,\n",
       "  2037,\n",
       "  4039,\n",
       "  3854,\n",
       "  3113,\n",
       "  150,\n",
       "  586,\n",
       "  2330,\n",
       "  1116,\n",
       "  353,\n",
       "  1400,\n",
       "  1491,\n",
       "  1856,\n",
       "  3314,\n",
       "  956,\n",
       "  3810,\n",
       "  2939,\n",
       "  3549,\n",
       "  1894,\n",
       "  3465,\n",
       "  1558,\n",
       "  2121,\n",
       "  280,\n",
       "  1108,\n",
       "  324,\n",
       "  1282,\n",
       "  1017,\n",
       "  4056,\n",
       "  3922,\n",
       "  3387,\n",
       "  1245,\n",
       "  871,\n",
       "  3470,\n",
       "  1577,\n",
       "  2200,\n",
       "  596,\n",
       "  2372,\n",
       "  1282,\n",
       "  1018,\n",
       "  4060,\n",
       "  3940,\n",
       "  3457,\n",
       "  1528,\n",
       "  2002,\n",
       "  3898,\n",
       "  3289,\n",
       "  853,\n",
       "  3398,\n",
       "  1292,\n",
       "  1060,\n",
       "  132,\n",
       "  516,\n",
       "  2050,\n",
       "  4090,\n",
       "  4058,\n",
       "  3932,\n",
       "  3425,\n",
       "  1398,\n",
       "  1482,\n",
       "  1820,\n",
       "  3169,\n",
       "  376,\n",
       "  1492,\n",
       "  1858,\n",
       "  3324,\n",
       "  994,\n",
       "  3961,\n",
       "  3543,\n",
       "  1870,\n",
       "  3370,\n",
       "  1180,\n",
       "  609,\n",
       "  2422,\n",
       "  1483,\n",
       "  1822,\n",
       "  3177,\n",
       "  406,\n",
       "  1611,\n",
       "  2333,\n",
       "  1128,\n",
       "  402,\n",
       "  1596,\n",
       "  2273,\n",
       "  885,\n",
       "  3526,\n",
       "  1804,\n",
       "  3105,\n",
       "  118,\n",
       "  457,\n",
       "  1813,\n",
       "  3143,\n",
       "  269,\n",
       "  1062,\n",
       "  140,\n",
       "  545,\n",
       "  2166,\n",
       "  460,\n",
       "  1828,\n",
       "  3201,\n",
       "  502,\n",
       "  1994,\n",
       "  3866,\n",
       "  3162,\n",
       "  345,\n",
       "  1366,\n",
       "  1354,\n",
       "  1306,\n",
       "  1113,\n",
       "  344,\n",
       "  1362,\n",
       "  1338,\n",
       "  1241,\n",
       "  854,\n",
       "  3403,\n",
       "  1312,\n",
       "  1137,\n",
       "  439,\n",
       "  1742,\n",
       "  2858,\n",
       "  3228,\n",
       "  610,\n",
       "  2425,\n",
       "  1494,\n",
       "  1868,\n",
       "  3361,\n",
       "  1141,\n",
       "  454,\n",
       "  1801,\n",
       "  3095,\n",
       "  77,\n",
       "  295,\n",
       "  1168,\n",
       "  562,\n",
       "  2234,\n",
       "  730,\n",
       "  2906,\n",
       "  3418,\n",
       "  1370,\n",
       "  1371,\n",
       "  1374,\n",
       "  1388,\n",
       "  1441,\n",
       "  1654,\n",
       "  2505,\n",
       "  1814,\n",
       "  3147,\n",
       "  288,\n",
       "  1140,\n",
       "  449,\n",
       "  1781,\n",
       "  3014,\n",
       "  3850,\n",
       "  3100,\n",
       "  100,\n",
       "  387,\n",
       "  1535,\n",
       "  2029,\n",
       "  4008,\n",
       "  3730,\n",
       "  2618,\n",
       "  2266,\n",
       "  857,\n",
       "  3413,\n",
       "  1350,\n",
       "  1290,\n",
       "  1049,\n",
       "  88,\n",
       "  338,\n",
       "  1337,\n",
       "  1238,\n",
       "  842,\n",
       "  3354,\n",
       "  1114,\n",
       "  348,\n",
       "  1378,\n",
       "  1404,\n",
       "  1506,\n",
       "  1916,\n",
       "  3554,\n",
       "  1916,\n",
       "  3554,\n",
       "  1914,\n",
       "  3548,\n",
       "  1889,\n",
       "  3446,\n",
       "  1484,\n",
       "  1826,\n",
       "  3195,\n",
       "  480,\n",
       "  1906,\n",
       "  3514,\n",
       "  1754,\n",
       "  2905,\n",
       "  3414,\n",
       "  1354,\n",
       "  1308,\n",
       "  1122,\n",
       "  378,\n",
       "  1500,\n",
       "  1892,\n",
       "  3458,\n",
       "  1532,\n",
       "  2018,\n",
       "  3964,\n",
       "  3],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species_name botrytis_porri_gca_004786265\n",
      "__index_level_0__  int  1077855\n",
      "input_ids 298\n",
      "token_type_ids 298\n",
      "attention_mask 298\n"
     ]
    }
   ],
   "source": [
    "#print(train_data[0].values())\n",
    "for k, v in train_data[0].items():\n",
    "    if isinstance(v, str):\n",
    "        print(k, v)\n",
    "    elif isinstance(v, np.ndarray):\n",
    "        print(k, v.shape)\n",
    "    elif isinstance(v, int):\n",
    "        print(k, \" int \",  v)\n",
    "    else:\n",
    "        print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = train_data.remove_columns([\"species_name\", \"__index_level_0__\"])\n",
    "collate_fn = DataCollatorForLanguageModeling(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"zhihan1996/DNA_bert_6\", trust_remote_code=True))\n",
    "dataloader = DataLoader(train_data, batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`species_name` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717\u001b[0m, in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    715\u001b[0m is_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_tensor\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_tensor\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(dataloader)\n\u001b[0;32m----> 2\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/data/data_collator.py:729\u001b[0m, in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3035\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m   3006\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3007\u001b[0m     text: Union[TextInput, PreTokenizedInput, EncodedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3025\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m   3026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;129m@add_end_docstrings\u001b[39m(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_encode_plus\u001b[39m(\n\u001b[1;32m   3030\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3031\u001b[0m     batch_text_or_text_pairs: Union[\n\u001b[1;32m   3032\u001b[0m         List[TextInput],\n\u001b[1;32m   3033\u001b[0m         List[TextInputPair],\n\u001b[1;32m   3034\u001b[0m         List[PreTokenizedInput],\n\u001b[0;32m-> 3035\u001b[0m         List[PreTokenizedInputPair],\n\u001b[1;32m   3036\u001b[0m         List[EncodedInput],\n\u001b[1;32m   3037\u001b[0m         List[EncodedInputPair],\n\u001b[1;32m   3038\u001b[0m     ],\n\u001b[1;32m   3039\u001b[0m     add_special_tokens: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3040\u001b[0m     padding: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, PaddingStrategy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3041\u001b[0m     truncation: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, TruncationStrategy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3042\u001b[0m     max_length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3043\u001b[0m     stride: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   3044\u001b[0m     is_split_into_words: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3045\u001b[0m     pad_to_multiple_of: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3046\u001b[0m     return_tensors: Optional[Union[\u001b[38;5;28mstr\u001b[39m, TensorType]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3047\u001b[0m     return_token_type_ids: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3048\u001b[0m     return_attention_mask: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3049\u001b[0m     return_overflowing_tokens: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3050\u001b[0m     return_special_tokens_mask: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3051\u001b[0m     return_offsets_mapping: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3052\u001b[0m     return_length: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3053\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3054\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3055\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;124;03m    Tokenize and prepare for the model a list of sequences or a list of pairs of sequences.\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m            details in `encode_plus`).\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3072\u001b[0m     \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    176\u001b[0m class BatchEncoding(UserDict):\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     Holds the output of the [`~tokenization_utils_base.PreTrainedTokenizerBase.__call__`],\n\u001b[1;32m    179\u001b[0m     [`~tokenization_utils_base.PreTrainedTokenizerBase.encode_plus`] and\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m             initialization.\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[1;32m    203\u001b[0m     def __init__(\n\u001b[1;32m    204\u001b[0m         self,\n\u001b[1;32m    205\u001b[0m         data: Optional[Dict[str, Any]] = None,\n\u001b[1;32m    206\u001b[0m         encoding: Optional[Union[EncodingFast, Sequence[EncodingFast]]] = None,\n\u001b[1;32m    207\u001b[0m         tensor_type: Union[None, str, TensorType] = None,\n\u001b[1;32m    208\u001b[0m         prepend_batch_axis: bool = False,\n\u001b[1;32m    209\u001b[0m         n_sequences: Optional[int] = None,\n\u001b[0;32m--> 210\u001b[0m     ):\n\u001b[1;32m    211\u001b[0m         super().__init__(data)\n\u001b[1;32m    213\u001b[0m         if isinstance(encoding, EncodingFast):\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:733\u001b[0m, in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_tensor\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 733\u001b[0m         value_lens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(value_lens)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m             \u001b[38;5;66;03m# we have a ragged list so handle explicitly\u001b[39;00m\n\u001b[1;32m    736\u001b[0m             value \u001b[38;5;241m=\u001b[39m as_tensor([np\u001b[38;5;241m.\u001b[39masarray(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m value], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`species_name` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "iterator = iter(dataloader)\n",
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species_name': ['botrytis_porri_gca_004786265',\n",
       "  'neolecta_irregularis_dah_3_gca_001929475',\n",
       "  'pyrrhoderma_noxium_gca_002287475',\n",
       "  'amanita_muscaria_koide_bx008_gca_000827485',\n",
       "  'aspergillus_tanneri_gca_004798825',\n",
       "  'pseudogymnoascus_sp_24mn13_gca_001662595',\n",
       "  'cryptococcus_neoformans_var_grubii_ad2_60a_gca_002215775',\n",
       "  'aspergillus_sclerotialis_gca_003589665',\n",
       "  'pseudozyma_hubeiensis_sy62_gca_000403515',\n",
       "  'aspergillus_alliaceus_gca_009176365',\n",
       "  'neolentinus_lepideus_hhb14362_ss_1_gca_001632425',\n",
       "  'aspergillus_sclerotialis_gca_003589665',\n",
       "  'aspergillus_niger_gca_002211485',\n",
       "  'colletotrichum_simmondsii_gca_001563135',\n",
       "  'eutypa_lata_ucrel1_gca_000349385',\n",
       "  'nematocida_sp_1_ertm6_gca_000738915'],\n",
       " '__index_level_0__': tensor([ 1077855, 12022999,  3833447,  7754371,  9910879,  4541058, 10267684,\n",
       "          7483640,  4566209,  6273196, 12141004,  7475231,  7220192, 11665496,\n",
       "          3894532,  9265708]),\n",
       " 'input_ids': [tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       "  tensor([4203, 5278, 4462, 4862, 5072, 4534, 5108, 4837, 4536, 4710, 5290, 4837,\n",
       "          4813, 5245, 4469, 5010]),\n",
       "  tensor([1030, 1055, 1262, 1242, 1081, 1846, 1056, 1088, 1845, 1815, 1069, 1092,\n",
       "          1276, 1810, 1047, 1045]),\n",
       "  tensor([  12,  110,  937,  859,  214, 3276,  116,  243, 3272, 3150,  167,  260,\n",
       "           993, 3130,   79,   69]),\n",
       "  tensor([  33,  426, 3735, 3422,  841,  803,  450,  959,  787,  298,  655, 1025,\n",
       "          3958,  220,  303,  261]),\n",
       "  tensor([ 120, 1691, 2639, 1385, 3352, 3200, 1787, 3823, 3136, 1180, 2605, 4085,\n",
       "          3532,  866, 1197, 1029]),\n",
       "  tensor([ 466, 2653, 2349, 1431, 1105,  499, 3038, 2990,  244,  612, 2214, 4037,\n",
       "          1827, 3450,  678,    6]),\n",
       "  tensor([1850, 2406, 1190, 1613,  312, 1984, 3946, 3755,  962, 2436,  650, 3847,\n",
       "          3197, 1500, 2700,   12]),\n",
       "  tensor([3292, 1418,  650, 2341, 1234, 3826, 3481, 2718, 3836, 1540, 2586, 3086,\n",
       "           486, 1892, 2595,   35]),\n",
       "  tensor([ 865, 1562, 2588, 1160,  828, 3004, 1622, 2667, 3041, 2052, 2139,   44,\n",
       "          1930, 3457, 2176,  128]),\n",
       "  tensor([3445, 2139, 2145,  530, 3300, 3810, 2380, 2463, 3960, 4097,  351,  161,\n",
       "          3610, 1526,  497,  498]),\n",
       "  tensor([1478,  350,  375, 2108,  899, 2940, 1316, 1648, 3539, 4087, 1391,  631,\n",
       "          2138, 1993, 1976, 1978]),\n",
       "  tensor([1804, 1386, 1485,  225, 3584, 3556, 1154, 2482, 1853, 4048, 1455, 2509,\n",
       "           348, 3864, 3795, 3801]),\n",
       "  tensor([3108, 1435, 1830,  886, 2036, 1923,  508, 1722, 3304, 3892, 1709, 1829,\n",
       "          1378, 3155, 2879, 2903]),\n",
       "  tensor([ 129, 1632, 3210, 3530, 4034, 3581, 2020, 2779,  914, 3266, 2725, 3207,\n",
       "          1402,  318, 3310, 3405]),\n",
       "  tensor([ 502, 2420,  540, 1817, 3833, 2021, 3970, 2910, 3642,  764, 2694,  526,\n",
       "          1499, 1258,  938, 1317]),\n",
       "  tensor([1994, 1475, 2146, 3158, 3030, 3976, 3577, 3436, 2267, 3044, 2569, 2090,\n",
       "          1887,  923, 3737, 1157]),\n",
       "  tensor([3868, 1792,  379,  330, 3916, 3604, 2006, 1441,  864, 3970, 2069,  153,\n",
       "          3438, 3679, 2645,  518]),\n",
       "  tensor([3169, 3058, 1501, 1306, 3362, 2115, 3914, 1654, 3442, 3578,   71,  598,\n",
       "          1450, 2414, 2374, 2057]),\n",
       "  tensor([ 373, 4026, 1895, 1113, 1146,  255, 3355, 2506, 1467, 2010,  270, 2379,\n",
       "          1692, 1452, 1292,   22]),\n",
       "  tensor([1477, 3801, 3470,  343,  475, 1005, 1117, 1818, 1760, 3931, 1066, 1309,\n",
       "          2658, 1697, 1057,   73]),\n",
       "  tensor([1797, 2902, 1579, 1360, 1885, 4007,  359, 3162, 2930, 3424,  153, 1128,\n",
       "          2428, 2680,  117,  279]),\n",
       "  tensor([3078, 3403, 2206, 1332, 3430, 3726, 1422,  347, 3515, 1396,  597,  401,\n",
       "          1505, 2516,  453, 1101]),\n",
       "  tensor([   9, 1310,  620, 1218, 1418, 2601, 1580, 1376, 1758, 1475, 2374, 1592,\n",
       "          1909, 1860, 1797,  296]),\n",
       "  tensor([  22, 1130, 2466,  761, 1562, 2200, 2209, 1394, 2922, 1792, 1292, 2257,\n",
       "          3527, 3329, 3079, 1170]),\n",
       "  tensor([  74,  411, 1657, 3030, 2138,  596,  629, 1466, 3482, 3060, 1058,  822,\n",
       "          1806, 1013,   13,  570]),\n",
       "  tensor([ 281, 1630, 2518, 3916,  345, 2370, 2501, 1754, 1627, 4036,  121, 3276,\n",
       "          3116, 4038,   39, 2266]),\n",
       "  tensor([1112, 2412, 1866, 3364, 1365, 1273, 1798, 2907, 2398, 3844,  469,  801,\n",
       "           162, 3850,  143,  858]),\n",
       "  tensor([ 337, 1442, 3353, 1156, 1352,  981, 3084, 3423, 1387, 3076, 1863, 3190,\n",
       "           634, 3100,  557, 3417]),\n",
       "  tensor([1334, 1658, 1109,  513, 1298, 3910,   34, 1390, 1438, 4097, 3343,  458,\n",
       "          2522,   97, 2214, 1368]),\n",
       "  tensor([1226, 2522,  327, 2038, 1081, 3338,  124, 1450, 1642, 4088, 1071, 1820,\n",
       "          1883,  375,  652, 1361]),\n",
       "  tensor([ 794, 1883, 1293, 4041,  216, 1049,  482, 1690, 2459, 4049,  174, 3170,\n",
       "          3424, 1485, 2594, 1334]),\n",
       "  tensor([3161, 3422, 1064, 3862,  849,   88, 1914, 2650, 1629, 3894,  682,  379,\n",
       "          1394, 1830, 2170, 1228]),\n",
       "  tensor([ 343, 1387,  148, 3145, 3382,  339, 3548, 2394, 2406, 3274, 2714, 1503,\n",
       "          1466, 3210,  476,  801]),\n",
       "  tensor([1357, 1437,  578,  279, 1225, 1344, 1892, 1371, 1417,  794, 2651, 1901,\n",
       "          1755,  538, 1889, 3190]),\n",
       "  tensor([1317, 1639, 2297, 1102,  790, 1267, 3460, 1375, 1558, 3164, 2399, 3496,\n",
       "          2911, 2140, 3448,  457]),\n",
       "  tensor([1160, 2446,  981,  298, 3147,  960, 1540, 1390, 2121,  356, 1391, 1684,\n",
       "          3438,  356, 1491, 1814]),\n",
       "  tensor([ 531, 1578, 3911, 1178,  287, 3827, 2050, 1450,  279, 1412, 1455, 2626,\n",
       "          1449, 1412, 1856, 3147]),\n",
       "  tensor([2112, 2202, 3344,  601, 1133, 3005, 4090, 1690, 1103, 1540, 1710, 2299,\n",
       "          1686, 1539, 3314,  285]),\n",
       "  tensor([ 242,  604, 1076, 2392,  422, 3816, 4060, 2650,  303, 2050, 2730,  992,\n",
       "          2633, 2046,  955, 1128]),\n",
       "  tensor([ 953, 2402,  193, 1362, 1675, 2961, 3937, 2394, 1198, 4090, 2715, 3955,\n",
       "          2328, 4076, 3805,  402]),\n",
       "  tensor([3798, 1402,  758, 1337, 2589, 3638, 3446, 1371,  684, 4060, 2655, 3518,\n",
       "          1106, 4003, 2920, 1594]),\n",
       "  tensor([2889, 1499, 3018, 1237, 2149, 2252, 1481, 1376, 2721, 3937, 2414, 1772,\n",
       "           315, 3712, 3476, 2266]),\n",
       "  tensor([3349, 1885, 3866,  837,  389,  804, 1814, 1395, 2679, 3448, 1449, 2977,\n",
       "          1246, 2548, 1604,  857]),\n",
       "  tensor([1096, 3429, 3162, 3334, 1543, 3202, 3148, 1471, 2509, 1490, 1686, 3701,\n",
       "           874, 1987, 2305, 3414]),\n",
       "  tensor([ 276, 1414,  346, 1035, 2061,  508,  292, 1774, 1830, 1850, 2635, 2501,\n",
       "          3483, 3839, 1016, 1353]),\n",
       "  tensor([1089, 1548, 1370,   30,   37, 2017, 1154, 2987, 3212, 3292, 2335, 1800,\n",
       "          1631, 3056, 4050, 1302]),\n",
       "  tensor([ 246, 2084, 1370,  106,  133, 3958,  508, 3743,  547,  866, 1135, 3091,\n",
       "          2415, 4020, 3898, 1097]),\n",
       "  tensor([ 971,  129, 1370,  409,  519, 3529, 2019, 2670, 2175, 3452,  429,   64,\n",
       "          1456, 3780, 3292,  278]),\n",
       "  tensor([3870,  501, 1370, 1622, 2062, 1816, 3966, 2473,  493, 1506, 1702,  241,\n",
       "          1713, 2818,  868, 1097]),\n",
       "  tensor([3179, 1990, 1370, 2378,   41, 3156, 3561, 1687, 1958, 1915, 2699,  949,\n",
       "          2742, 3068, 3460,  280]),\n",
       "  tensor([ 416, 3850, 1370, 1308,  149,  322, 1942, 2639, 3722, 3551, 2589, 3783,\n",
       "          2762, 4068, 1537, 1105]),\n",
       "  tensor([1650, 3100, 1370, 1124,  582, 1276, 3659, 2350, 2585, 1904, 2150, 2831,\n",
       "          2842, 3972, 2040,  310]),\n",
       "  tensor([2492,   99, 1370,  387, 2313,  994, 2334, 1195, 2136, 3506,  395, 3120,\n",
       "          3164, 3585, 4052, 1228]),\n",
       "  tensor([1761,  381, 1371, 1533, 1045, 3961, 1130,  671,  339, 1723, 1566,  179,\n",
       "           354, 2039, 3905,  803]),\n",
       "  tensor([2934, 1509, 1373, 2024,   69, 3542,  412, 2670, 1343, 2781, 2153,  702,\n",
       "          1403, 4045, 3317, 3197]),\n",
       "  tensor([3531, 1928, 1381, 3985,  263, 1866, 1634, 2474, 1263, 2919,  407, 2794,\n",
       "          1501, 3877,  966,  485]),\n",
       "  tensor([1823, 3604, 1413, 3638, 1037, 3354, 2426, 1690,  942, 3470, 1614, 2971,\n",
       "          1893, 3208, 3851, 1928]),\n",
       "  tensor([3182, 2113, 1541, 2249,   38, 1113, 1498, 2651, 3754, 1579, 2347, 3677,\n",
       "          3461,  530, 3101, 3604]),\n",
       "  tensor([ 426,  245, 2053,  790,  137,  344, 1884, 2400, 2714, 2206, 1184, 2407,\n",
       "          1543, 2107,  104, 2115]),\n",
       "  tensor([1691,  966,    5, 3148,  536, 1362, 3426, 1395, 2649,  618,  625, 1421,\n",
       "          2062,  221,  402,  254]),\n",
       "  tensor([2654, 3851,    6,  291, 2131, 1338, 1401, 1471, 2391, 2459, 2488, 1575,\n",
       "            41,  870, 1595, 1002]),\n",
       "  tensor([2411, 3102,   12, 1149,  320, 1243, 1494, 1774, 1358, 1630, 1748, 2189,\n",
       "           150, 3465, 2272, 3996]),\n",
       "  tensor([1438,  107,   36,  486, 1268,  861, 1866, 2986, 1323, 2410, 2883,  550,\n",
       "           586, 1559,  882, 3681]),\n",
       "  tensor([1642,  414,  129, 1930,  962, 3431, 3353, 3739, 1182, 1433, 3328, 2187,\n",
       "          2329, 2127, 3516, 2421]),\n",
       "  tensor([2458, 1642,  502, 3612, 3835, 1422, 1110, 2656,  618, 1621, 1011,  543,\n",
       "          1112,  303, 1762, 1477]),\n",
       "  tensor([1626, 2458, 1996, 2148, 3040, 1579,  332, 2417, 2459, 2376, 4029, 2158,\n",
       "           338, 1200, 2940, 1797]),\n",
       "  tensor([2394, 1627, 3873,  388, 3954, 2206, 1316, 1463, 1629, 1297, 3813,  426,\n",
       "          1339,  691, 3556, 3078]),\n",
       "  tensor([1370, 2398, 3190, 1537, 3513,  620, 1154, 1742, 2407, 1078, 2951, 1690,\n",
       "          1247, 2749, 1921,   11]),\n",
       "  tensor([1371, 1388,  457, 2038, 1749, 2467,  506, 2858, 1422,  202, 3599, 2650,\n",
       "           880, 2789, 3576,   29]),\n",
       "  tensor([1375, 1442, 1814, 4041, 2886, 1662, 2010, 3226, 1579,  794, 2095, 2393,\n",
       "          3506, 2950, 2004,  104]),\n",
       "  tensor([1390, 1658, 3145, 3861, 3340, 2537, 3929,  604, 2208, 3161,  174, 1367,\n",
       "          1724, 3593, 3905,  403]),\n",
       "  tensor([1450, 2521,  278, 3142, 1060, 1944, 3416, 2402,  626,  343,  681, 1357,\n",
       "          2786, 2071, 3320, 1599]),\n",
       "  tensor([1691, 1879, 1099,  268,  131, 3666, 1361, 1401, 2490, 1360, 2711, 1319,\n",
       "          2938,   77,  980, 2285]),\n",
       "  tensor([2655, 3406,  285, 1060,  511, 2361, 1336, 1495, 1756, 1332, 2637, 1168,\n",
       "          3546,  295, 3908,  933]),\n",
       "  tensor([2414, 1324, 1125,  129, 2029, 1240, 1233, 1871, 2914, 1220, 2341,  563,\n",
       "          1883, 1165, 3331, 3717]),\n",
       "  tensor([1451, 1188,  390,  501, 4005,  851,  821, 3374, 3449,  772, 1158, 2238,\n",
       "          3421,  549, 1023, 2566]),\n",
       "  tensor([1694,  641, 1547, 1990, 3719, 3389, 3270, 1196, 1494, 3074,  524,  748,\n",
       "          1384, 2183, 4079, 2057]),\n",
       "  tensor([2666, 2550, 2078, 3849, 2575, 1253,  777,  673, 1866, 4092, 2081, 2979,\n",
       "          1425,  527, 4014,   23]),\n",
       "  tensor([2459, 1994,  106, 3096, 2096,  902, 3093, 2678, 3355, 4065,  120, 3710,\n",
       "          1592, 2094, 3753,   79]),\n",
       "  tensor([1630, 3865,  412,   82,  178, 3596,   71, 2505, 1118, 3960,  466, 2540,\n",
       "          2257,  170, 2712,  303]),\n",
       "  tensor([2410, 3160, 1634,  315,  697, 2082,  270, 1815,  361, 3540, 1852, 1955,\n",
       "           823,  668, 2642, 1197]),\n",
       "  tensor([1434,  340, 2426, 1245, 2775,  124, 1066, 3150, 1430, 1860, 3299, 3709,\n",
       "          3277, 2657, 2363,  680]),\n",
       "  tensor([1627, 1347, 1498,  869, 2895,  483,  154,  299, 1610, 3330,  896, 2536,\n",
       "           808, 2421, 1245, 2705]),\n",
       "  tensor([2398, 1278, 1884, 3462, 3373, 1917,  601, 1183, 2331, 1020, 3571, 1937,\n",
       "          3220, 1480,  872, 2613]),\n",
       "  tensor([1386, 1002, 3428, 1548, 1190, 3558, 2390,  624, 1119, 4066, 1981, 3637,\n",
       "           580, 1809, 3476, 2245]),\n",
       "  tensor([1434, 3993, 1409, 2082,  651, 1930, 1353, 2481,  367, 3962, 3816, 2248,\n",
       "          2308, 3127, 1604,  774]),\n",
       "  tensor([1626, 3670, 1525,  121, 2589, 3610, 1304, 1719, 1453, 3545, 2963,  787,\n",
       "          1026,  207, 2306, 3082]),\n",
       "  tensor([2395, 2379, 1990,  469, 2152, 2138, 1106, 2765, 1702, 1877, 3645, 3135,\n",
       "          4091,  813, 1020,   25]),\n",
       "  tensor([1374, 1310, 3852, 1861,  401,  345,  314, 2855, 2697, 3398, 2277,  238,\n",
       "          4063, 3239, 4067,   87]),\n",
       "  tensor([1388, 1130, 3108, 3333, 1589, 1366, 1244, 3215, 2582, 1290,  903,  939,\n",
       "          3949,  656, 3965,  333]),\n",
       "  tensor([1444,  410,  132, 1029, 2245, 1356,  865,  560, 2122, 1050, 3599, 3741,\n",
       "          3496, 2612, 3557, 1319]),\n",
       "  tensor([1668, 1625,  513,    5,  775, 1314, 3445, 2225,  284,   91, 2095, 2662,\n",
       "          1683, 2244, 1927, 1167]),\n",
       "  tensor([2561, 2391, 2037,    8, 3085, 1147, 1477,  693, 1123,  350,  176, 2442,\n",
       "          2623,  769, 3599,  557]),\n",
       "  tensor([2037, 1359, 4038,   19,   37,  478, 1798, 2758,  381, 1387,  691, 1564,\n",
       "          2288, 3061, 2094, 2214]),\n",
       "  tensor([4039, 1325, 3850,   61,  135, 1898, 3083, 2828, 1510, 1439, 2749, 2145,\n",
       "           946, 4040,  170,  651]),\n",
       "  tensor([3854, 1190, 3097,  230,  527, 3483,   30, 3105, 1930, 1648, 2791,  374,\n",
       "          3771, 3857,  667, 2592]),\n",
       "  tensor([3113,  650,   87,  908, 2094, 1630,  108,  117, 3610, 2484, 2959, 1483,\n",
       "          2783, 3126, 2656, 2163]),\n",
       "  tensor([ 150, 2588,  336, 3620,  171, 2412,  420,  454, 2138, 1729, 3630, 1821,\n",
       "          2925,  204, 2419,  448]),\n",
       "  tensor([ 586, 2146, 1331, 2177,  669, 1441, 1666, 1803,  348, 2808, 2219, 3175,\n",
       "          3496,  802, 1470, 1779]),\n",
       "  tensor([2330,  378, 1213,  503, 2662, 1653, 2555, 3102, 1380, 3028,  670,  398,\n",
       "          1682, 3195, 1771, 3007]),\n",
       "  tensor([1116, 1498,  741, 1998, 2443, 2501, 2016,  107, 1409, 3908, 2668, 1578,\n",
       "          2620,  477, 2975, 3821]),\n",
       "  tensor([ 353, 1882, 2949, 3883, 1565, 1798, 3955,  415, 1526, 3332, 2467, 2202,\n",
       "          2276, 1894, 3694, 2981]),\n",
       "  tensor([1400, 3418, 3589, 3229, 2149, 3081, 3519, 1645, 1995, 1027, 1664,  604,\n",
       "           899, 3466, 2475, 3720]),\n",
       "  tensor([1491, 1371, 2056,  613,  391,   21, 1776, 2469, 3870, 4093, 2545, 2404,\n",
       "          3581, 1561, 1695, 2579]),\n",
       "  tensor([1856, 1374,   20, 2438, 1550,   72, 2995, 1669, 3179, 4069, 1976, 1409,\n",
       "          2021, 2135, 2669, 2109]),\n",
       "  tensor([3314, 1388,   68, 1545, 2089,  276, 3776, 2565,  414, 3974, 3796, 1527,\n",
       "          3974,  333, 2472,  230]),\n",
       "  tensor([ 956, 1444,  257, 2069,  150, 1091, 2802, 2053, 1642, 3596, 2881, 1999,\n",
       "          3596, 1318, 1682,  905]),\n",
       "  tensor([3810, 1667, 1016,   70,  586,  256, 3001,    8, 2458, 2082, 3318, 3885,\n",
       "          2083, 1163, 2620, 3606]),\n",
       "  tensor([2939, 2560, 4049,  265, 2331, 1009, 3797,   20, 1628,  122,  969, 3237,\n",
       "           126,  544, 2276, 2124]),\n",
       "  tensor([3549, 2034, 3893, 1045, 1118, 4024, 2886,   68, 2403,  476, 3862,  648,\n",
       "           489, 2162,  900,  291]),\n",
       "  tensor([1894, 4026, 3272,   71,  363, 3796, 3339,  257, 1407, 1889, 3146, 2578,\n",
       "          1942,  442, 3588, 1150]),\n",
       "  tensor([3465, 3804,  786,  272, 1440, 2882, 1056, 1013, 1520, 3448,  283, 2105,\n",
       "          3657, 1755, 2052,  492]),\n",
       "  tensor([1558, 2916, 3131, 1075, 1651, 3322,  114, 4037, 1971, 1492, 1117,  214,\n",
       "          2325, 2911, 4099, 1956]),\n",
       "  tensor([2121, 3458,  222,  190, 2493,  986,  442, 3845, 3774, 1858,  357,  841,\n",
       "          1095, 3437, 4093, 3715]),\n",
       "  tensor([ 280, 1530,  873,  747, 1765, 3929, 1753, 3077, 2795, 3322, 1415, 3351,\n",
       "           269, 1447, 4072, 2558]),\n",
       "  tensor([1108, 2009, 3478, 2976, 2950, 3414, 2903,    5, 2973,  988, 1549, 1101,\n",
       "          1061, 1677, 3985, 2026]),\n",
       "  tensor([ 324, 3926, 1610, 3700, 3593, 1354, 3406,    5, 3685, 3940, 2086,  296,\n",
       "           134, 2600, 3639, 3994]),\n",
       "  tensor([1282, 3404, 2330, 2497, 2070, 1305, 1322,    8, 2439, 3457,  137, 1169,\n",
       "           524, 2194, 2256, 3676]),\n",
       "  tensor([1017, 1313, 1116, 1784,   75, 1112, 1180,   17, 1549, 1526,  535,  565,\n",
       "          2084,  569,  819, 2404]),\n",
       "  tensor([4056, 1142,  356, 3025,  285,  338,  610,   53, 2086, 1994, 2126, 2247,\n",
       "           129, 2262, 3262, 1411]),\n",
       "  tensor([3922,  458, 1409, 3893, 1126, 1340, 2428,  198,  140, 3865,  299,  783,\n",
       "           502,  842,  746, 1536]),\n",
       "  tensor([3387, 1820, 1526, 3272,  394, 1249, 1506,  777,  548, 3158, 1182, 3120,\n",
       "          1993, 3354, 2970, 2034]),\n",
       "  tensor([1245, 3171, 1994,  785, 1562,  888, 1914, 3093, 2178,  332,  619,  179,\n",
       "          3863, 1115, 3676, 4025]),\n",
       "  tensor([ 871,  381, 3866, 3125, 2140, 3540, 3545,   70,  507, 1313, 2461,  703,\n",
       "          3149,  350, 2401, 3798]),\n",
       "  tensor([3470, 1509, 3162,  197,  355, 1858, 1878,  267, 2014, 1142, 1637, 2797,\n",
       "           294, 1388, 1397, 2891]),\n",
       "  tensor([1577, 1925,  348,  774, 1405, 3322, 3404, 1054, 3946,  460, 2439, 2982,\n",
       "          1164, 1442, 1478, 3357]),\n",
       "  tensor([2200, 3590, 1379, 3082, 1511,  988, 1316,  105, 3483, 1825, 1552, 3723,\n",
       "           545, 1659, 1801, 1128]),\n",
       "  tensor([ 596, 2057, 1405,   25, 1935, 3939, 1153,  407, 1631, 3189, 2097, 2589,\n",
       "          2166, 2526, 3095,  401]),\n",
       "  tensor([2372,   21, 1512,   87, 3629, 3454,  502, 1616, 2416,  456,  183, 2152,\n",
       "           458, 1898,   78, 1589]),\n",
       "  tensor([1282,   69, 1938,  334, 2215, 1514, 1996, 2356, 1459, 1812,  719,  404,\n",
       "          1817, 3483,  298, 2245]),\n",
       "  tensor([1018,  261, 3641, 1321,  654, 1946, 3876, 1217, 1725, 3139, 2863, 1602,\n",
       "          3160, 1631, 1178,  773]),\n",
       "  tensor([4060, 1030, 2262, 1175, 2604, 3674, 3204,  759, 2792,  256, 3247, 2299,\n",
       "           337, 2414,  601, 3077]),\n",
       "  tensor([3940,   10,  841,  589, 2211, 2393,  514, 3023, 2961, 1010,  685,  991,\n",
       "          1333, 1451, 2390,    6]),\n",
       "  tensor([3457,   26, 3352, 2342,  637, 1366, 2043, 3888, 3637, 4028, 2726, 3952,\n",
       "          1221, 1693, 1353,   11]),\n",
       "  tensor([1528,   92, 1106, 1163, 2535, 1354, 4062, 3252, 2245, 3809, 2699, 3507,\n",
       "           773, 2661, 1303,   31]),\n",
       "  tensor([2002,  353,  314,  541, 1936, 1305, 3945,  708,  774, 2933, 2590, 1727,\n",
       "          3077, 2439, 1102,  109]),\n",
       "  tensor([3898, 1398, 1241, 2152, 3633, 1112, 3479, 2817, 3083, 3528, 2155, 2798,\n",
       "             8, 1551,  300,  422]),\n",
       "  tensor([3289, 1484,  856,  404, 2230,  338, 1616, 3063,   29, 1809,  413, 2987,\n",
       "            19, 2094, 1188, 1673]),\n",
       "  tensor([ 853, 1828, 3410, 1603,  715, 1338, 2355, 4045,  102, 3125, 1637, 3742,\n",
       "            63,  171,  642, 2581]),\n",
       "  tensor([3398, 3203, 1340, 2302, 2847, 1244, 1216, 3878,  395,  199, 2439, 2668,\n",
       "           237,  669, 2555, 2117]),\n",
       "  tensor([1292,  511, 1249, 1002, 3182,  865,  755, 3209, 1565,  784, 1551, 2465,\n",
       "           936, 2661, 2015,  262]),\n",
       "  tensor([1060, 2029,  888, 3995,  426, 3448, 3006,  534, 2150, 3122, 2094, 1653,\n",
       "          3729, 2439, 3949, 1034]),\n",
       "  tensor([ 132, 4006, 3539, 3680, 1691, 1489, 3817, 2121,  396,  188,  172, 2503,\n",
       "          2614, 1549, 3493,   28]),\n",
       "  tensor([ 516, 3721, 1856, 2417, 2655, 1847, 2965,  279, 1571,  737,  675, 1808,\n",
       "          2250, 2085, 1670,   97]),\n",
       "  tensor([2050, 2581, 3313, 1462, 2414, 3277, 3656, 1102, 2174, 2933, 2686, 3123,\n",
       "           794,  133, 2572,  373]),\n",
       "  tensor([4090, 2118,  951, 1739, 1451,  806, 2321,  300,  492, 3526, 2540,  191,\n",
       "          3161,  518, 2083, 1477]),\n",
       "  tensor([4058,  268, 3789, 2845, 1693, 3211, 1077, 1188, 1953, 1802, 1954,  749,\n",
       "           341, 2060,  126, 1797]),\n",
       "  tensor([3932, 1057, 2853, 3174, 2663,  541,  198,  644, 3704, 3097, 3707, 2982,\n",
       "          1350,   35,  489, 3077]),\n",
       "  tensor([3425,  118, 3208,  394, 2446, 2152,  777, 2561, 2516,   85, 2528, 3721,\n",
       "          1291,  126, 1942,    6]),\n",
       "  tensor([1398,  457,  531, 1562, 1579,  403, 3094, 2037, 1857,  328, 1907, 2582,\n",
       "          1053,  491, 3660,   10]),\n",
       "  tensor([1482, 1813, 2112, 2140, 2206, 1598,   75, 4039, 3320, 1299, 3519, 2124,\n",
       "           103, 1949, 2339,   26]),\n",
       "  tensor([1820, 3142,  241,  353,  618, 2282,  285, 3856,  979, 1087, 1773,  290,\n",
       "           400, 3688, 1150,   90]),\n",
       "  tensor([3169,  266,  950, 1398, 2460,  924, 1126, 3124, 3904,  238, 2982, 1145,\n",
       "          1585, 2449,  489,  345]),\n",
       "  tensor([ 376, 1051, 3788, 1483, 1636, 3682,  396,  196, 3314,  937, 3721,  471,\n",
       "          2231, 1589, 1943, 1366]),\n",
       "  tensor([1492,   94, 2849, 1821, 2436, 2428, 1571,  771,  955, 3734, 2583, 1872,\n",
       "           717, 2245, 3663, 1353]),\n",
       "  tensor([1858,  364, 3191, 3174, 1540, 1508, 2173, 3072, 3806, 2635, 2127, 3377,\n",
       "          2854,  774, 2351, 1302]),\n",
       "  tensor([3324, 1442,  462,  395, 2051, 1923,  488, 4083, 2922, 2334,  303, 1206,\n",
       "          3210, 3081, 1199, 1098]),\n",
       "  tensor([ 994, 1658, 1834, 1568, 4095, 3582, 1938, 4030, 3484, 1132, 1200,  713,\n",
       "           538,   24,  686,  283]),\n",
       "  tensor([3961, 2521, 3226, 2163, 4077, 2026, 3643, 3818, 1633,  417,  691, 2838,\n",
       "          2139,   82, 2730, 1118]),\n",
       "  tensor([3543, 1877,  602,  446, 4006, 3995, 2270, 2970, 2421, 1656, 2751, 3148,\n",
       "           351,  314, 2716,  362]),\n",
       "  tensor([1870, 3397, 2393, 1772, 3723, 3677,  873, 3676, 1480, 2513, 2799,  290,\n",
       "          1390, 1242, 2660, 1436]),\n",
       "  tensor([3370, 1286, 1365, 2977, 2589, 2408, 3477, 2403, 1811, 1846, 2991, 1146,\n",
       "          1449,  858, 2436, 1636]),\n",
       "  tensor([1180, 1033, 1349, 3703, 2149, 1425, 1606, 1406, 3136, 3273, 3759,  473,\n",
       "          1686, 3418, 1537, 2435]),\n",
       "  tensor([ 609,   24, 1288, 2510,  389, 1590, 2313, 1514,  242,  789, 2734, 1878,\n",
       "          2634, 1372, 2037, 1533]),\n",
       "  tensor([2422,   81, 1041, 1833, 1544, 2250, 1046, 1948,  955, 3144, 2731, 3402,\n",
       "          2332, 1377, 4039, 2022]),\n",
       "  tensor([1483,  310,   53, 3221, 2067,  794,   73, 3683, 3808,  276, 2718, 1307,\n",
       "          1122, 1398, 3853, 3980]),\n",
       "  tensor([1822, 1225,  198,  582,   61, 3161,  278, 2429, 2929, 1091, 2667, 1118,\n",
       "           378, 1484, 3111, 3620]),\n",
       "  tensor([3177,  789,  779, 2315,  230,  341, 1097, 1510, 3512,  254, 2464,  361,\n",
       "          1498, 1825,  143, 2178]),\n",
       "  tensor([ 406, 3142, 3103, 1055,  908, 1350,  277, 1932, 1748, 1001, 1651, 1431,\n",
       "          1884, 3191,  557,  508]),\n",
       "  tensor([1611,  265,  111,  112, 3619, 1289, 1095, 3617, 2883, 3990, 2495, 1613,\n",
       "          3428,  464, 2214, 2017]),\n",
       "  tensor([2333, 1046,  429,  433, 2174, 1046,  270, 2166, 3327, 3659, 1775, 2342,\n",
       "          1410, 1842,  651, 3957]),\n",
       "  tensor([1128,   74, 1702, 1717,  489,   76, 1065,  460, 1008, 2334, 2989, 1163,\n",
       "          1529, 3259, 2592, 3527]),\n",
       "  tensor([ 402,  281, 2699, 2758, 1942,  289,  149, 1828, 4020, 1129, 3751,  543,\n",
       "          2005,  736, 2161, 1807]),\n",
       "  tensor([1596, 1110, 2591, 2826, 3657, 1142,  582, 3204, 3777,  407, 2701, 2160,\n",
       "          3912, 2931,  437, 3117]),\n",
       "  tensor([2273,  330, 2157, 3100, 2328,  459, 2315,  514, 2806, 1615, 2597,  435,\n",
       "          3348, 3520, 1736,  167]),\n",
       "  tensor([ 885, 1308,  422,   99, 1107, 1822, 1055, 2042, 3017, 2351, 2183, 1726,\n",
       "          1090, 1778, 2836,  654]),\n",
       "  tensor([3526, 1121, 1675,  384,  319, 3177,  110, 4058, 3864, 1199,  526, 2793,\n",
       "           249, 3003, 3138, 2603]),\n",
       "  tensor([1804,  373, 2591, 1521, 1262,  407,  427, 3931, 3155,  685, 2089, 2967,\n",
       "           984, 3807,  252, 2207]),\n",
       "  tensor([3105, 1480, 2160, 1976,  940, 1613, 1693, 3424,  318, 2728,  152, 3662,\n",
       "          3924, 2926,  996,  621]),\n",
       "  tensor([ 118, 1811,  434, 3795, 3748, 2341, 2662, 1395, 1260, 2705,  596, 2345,\n",
       "          3393, 3499, 3970, 2469]),\n",
       "  tensor([ 457, 3136, 1723, 2878, 2690, 1157, 2443, 1470,  930, 2616, 2370, 1175,\n",
       "          1270, 1695, 3580, 1669]),\n",
       "  tensor([1813,  241, 2783, 3305, 2553,  517, 1567, 1772, 3708, 2259, 1276,  590,\n",
       "           970, 2671, 2018, 2568]),\n",
       "  tensor([3143,  951, 2928,  917, 2007, 2055, 2157, 2978, 2530,  830,  996, 2345,\n",
       "          3866, 2478, 3964, 2068]),\n",
       "  tensor([ 269, 3791, 3506, 3653, 3919,   13,  423, 3708, 1916, 3305, 3971, 1174,\n",
       "          3161, 1706, 3556,   65]),\n",
       "  tensor([1062, 2863, 1723, 2309, 3373,   38, 1680, 2529, 3553,  917, 3584,  588,\n",
       "           342, 2715, 1923,  245]),\n",
       "  tensor([ 140, 3246, 2783, 1029, 1189,  137, 2609, 1910, 1910, 3656, 2035, 2339,\n",
       "          1353, 2655, 3584,  968]),\n",
       "  tensor([ 545,  681, 2925,    6,  648,  534, 2230, 3529, 3531, 2324, 4031, 1152,\n",
       "          1301, 2415, 2034, 3859]),\n",
       "  tensor([2166, 2710, 3495,   10, 2579, 2121,  714, 1816, 1821, 1089, 3823,  497,\n",
       "          1093, 1453, 4027, 3134]),\n",
       "  tensor([ 460, 2635, 1677,   28, 2109,  278, 2844, 3153, 3173,  247, 2990, 1974,\n",
       "           261, 1702, 3806,  235]),\n",
       "  tensor([1828, 2335, 2600,   97,  229, 1098, 3169,  312,  389,  974, 3756, 3788,\n",
       "          1032, 2700, 2921,  925]),\n",
       "  tensor([3201, 1134, 2194,  375,  904,  284,  374, 1236, 1541, 3884, 2724, 2850,\n",
       "            18, 2593, 3477, 3685]),\n",
       "  tensor([ 502,  425,  569, 1486, 3604, 1123, 1481,  834, 2056, 3233, 2691, 3195,\n",
       "            57, 2165, 1606, 2437]),\n",
       "  tensor([1994, 1685, 2262, 1836, 2113,  381, 1814, 3322,   17,  632, 2557,  477,\n",
       "           214,  456, 2316, 1542]),\n",
       "  tensor([3866, 2632,  843, 3235,  245, 1511, 3146,  987,   55, 2516, 2021, 1895,\n",
       "           842, 1811, 1060, 2060]),\n",
       "  tensor([3162, 2323, 3357,  638,  968, 1934,  283, 3934,  208, 1859, 3973, 3470,\n",
       "          3354, 3134,  131,   35]),\n",
       "  tensor([ 345, 1086, 1126, 2537, 3860, 3625, 1120, 3436,  818, 3328, 3591, 1577,\n",
       "          1113,  236,  510,  125]),\n",
       "  tensor([1366,  236,  394, 1943, 3138, 2199,  370, 1444, 3260, 1012, 2063, 2198,\n",
       "           342,  931, 2028,  485]),\n",
       "  tensor([1354,  931, 1563, 3661,  252,  592, 1468, 1665,  737, 4034,   46,  585,\n",
       "          1354, 3710, 4004, 1925]),\n",
       "  tensor([1306, 3712, 2141, 2341,  993, 2356, 1763, 2551, 2936, 3836,  172, 2327,\n",
       "          1305, 2538, 3716, 3592]),\n",
       "  tensor([1113, 2548,  358, 1157, 3959, 1220, 2942, 1999, 3540, 3041,  674, 1103,\n",
       "          1110, 1946, 2564, 2067]),\n",
       "  tensor([ 344, 1987, 1418,  519, 3533,  769, 3562, 3888, 1860, 3960, 2681,  301,\n",
       "           329, 3676, 2049,   63]),\n",
       "  tensor([1362, 3837, 1562, 2063, 1829, 3063, 1947, 3252, 3332, 3539, 2518, 1192,\n",
       "          1301, 2401, 4087,  237]),\n",
       "  tensor([1338, 3046, 2137,   45, 3208, 4045, 3678,  705, 1027, 1853, 1868,  659,\n",
       "          1095, 1397, 4045,  936]),\n",
       "  tensor([1241, 3977,  342,  167,  532, 3877, 2410, 2806, 4093, 3303, 3362, 2621,\n",
       "           270, 1480, 3879, 3730]),\n",
       "  tensor([ 854, 3607, 1354,  655, 2114, 3205, 1435, 3020, 4069,  909, 1145, 2277,\n",
       "          1067, 1809, 3216, 2620]),\n",
       "  tensor([3403, 2128, 1306, 2605,  249,  520, 1630, 3875, 3976, 3623,  471,  903,\n",
       "           159, 3128,  561, 2273]),\n",
       "  tensor([1312,  307, 1115, 2214,  981, 2068, 2412, 3199, 3604, 2190, 1870, 3599,\n",
       "           622,  209, 2230,  885]),\n",
       "  tensor([1137, 1214,  351,  652, 3910,   68, 1443,  496, 2114,  553, 3370, 2096,\n",
       "          2476,  823,  715, 3528]),\n",
       "  tensor([ 439,  745, 1389, 2596, 3337,  259, 1663, 1971,  252, 2200, 1179,  180,\n",
       "          1698, 3279, 2846, 1809]),\n",
       "  tensor([1742, 2965, 1446, 2178, 1047, 1022, 2541, 3774,  994,  595,  607,  705,\n",
       "          2681,  813, 3179, 3128]),\n",
       "  tensor([2858, 3653, 1675,  505,   78, 4076, 1958, 2796, 3962, 2367, 2415, 2808,\n",
       "          2519, 3239,  413,  209]),\n",
       "  tensor([3228, 2312, 2590, 2005,  299, 4004, 3722, 2980, 3548, 1261, 1453, 3025,\n",
       "          1871,  655, 1640,  821]),\n",
       "  tensor([ 610, 1041, 2154, 3912, 1183, 3715, 2587, 3716, 1889,  933, 1703, 3893,\n",
       "          3373, 2605, 2450, 3269]),\n",
       "  tensor([2425,   54,  411, 3346,  624, 2558, 2142, 2561, 3448, 3718, 2702, 3270,\n",
       "          1189, 2216, 1594,  773]),\n",
       "  tensor([1494,  203, 1631, 1081, 2482, 2026,  362, 2038, 1492, 2570, 2601,  780,\n",
       "           647,  660, 2266, 3077]),\n",
       "  tensor([1868,  800, 2415,  214, 1722, 3996, 1434, 4042, 1860, 2073, 2199, 3105,\n",
       "          2575, 2626,  858,    8]),\n",
       "  tensor([3361, 3187, 1454,  844, 2780, 3684, 1628, 3867, 3329,   88,  591,  117,\n",
       "          2093, 2299, 3419,   18]),\n",
       "  tensor([1141,  446, 1707, 3361, 2915, 2436, 2404, 3167, 1013,  340, 2349,  456,\n",
       "           168,  991, 1374,   60]),\n",
       "  tensor([ 454, 1770, 2719, 1144, 3454, 1538, 1412,  368, 4037, 1348, 1191, 1809,\n",
       "           657, 3952, 1386,  225]),\n",
       "  tensor([1801, 2971, 2670,  467, 1516, 2042, 1540, 1460, 3847, 1281,  656, 3127,\n",
       "          2613, 3506, 1436,  886]),\n",
       "  tensor([3095, 3677, 2474, 1853, 1954, 4060, 2051, 1729, 3088, 1016, 2611,  205,\n",
       "          2248, 1722, 1636, 3532]),\n",
       "  tensor([  77, 2407, 1691, 3304, 3706, 3937, 4094, 2806,   51, 4052, 2238,  808,\n",
       "           788, 2780, 2434, 1825]),\n",
       "  tensor([ 295, 1421, 2653,  915, 2522, 3447, 4075, 3017,  189, 3908,  745, 3217,\n",
       "          3140, 2913, 1529, 3192]),\n",
       "  tensor([1168, 1576, 2406, 3648, 1883, 1486, 3997, 3862,  744, 3331, 2967,  568,\n",
       "           259, 3446, 2007,  468]),\n",
       "  tensor([ 562, 2193, 1417, 2292, 3423, 1836, 3688, 3145, 2964, 1021, 3663, 2259,\n",
       "          1024, 1484, 3920, 1859]),\n",
       "  tensor([2234,  565, 1558,  961, 1389, 3233, 2451,  278, 3652, 4069, 2351,  829,\n",
       "          4081, 1825, 3377, 3325]),\n",
       "  tensor([ 730, 2245, 2124, 3829, 1447,  629, 1597, 1099, 2307, 3975, 1199, 3304,\n",
       "          4024, 3189, 1206, 1000]),\n",
       "  tensor([2906,  774,  291, 3015, 1680, 2501, 2277,  287, 1024, 3598,  687,  914,\n",
       "          3795,  453,  716, 3985]),\n",
       "  tensor([3418, 3084, 1152, 3855, 2610, 1797,  903, 1133, 4081, 2091, 2735, 3643,\n",
       "          2877, 1797, 2852, 3637]),\n",
       "  tensor([1370,   36,  497, 3119, 2235, 3080, 3598,  422, 4023,  157, 2736, 2272,\n",
       "          3304, 3080, 3204, 2248]),\n",
       "  tensor([1371,  130, 1976,  175,  735,   20, 2090, 1676, 3791,  614, 2738,  883,\n",
       "           916,   17,  516,  785]),\n",
       "  tensor([1374,  508, 3793,  686, 2927,   67,  155, 2594, 2864, 2444, 2745, 3517,\n",
       "          3649,   54, 2052, 3127]),\n",
       "  tensor([1388, 2018, 2869, 2731, 3501,  254,  606, 2169, 3250, 1570, 2775, 1767,\n",
       "          2296,  202, 4097,  205]),\n",
       "  tensor([1441, 3964, 3272, 2718, 1703, 1004, 2412,  471,  700, 2171, 2894, 2958,\n",
       "           978,  794, 4087,  805]),\n",
       "  tensor([1654, 3553,  787, 2668, 2701, 4003, 1444, 1869, 2787,  477, 3370, 3625,\n",
       "          3898, 3164, 4048, 3207]),\n",
       "  tensor([2505, 1911, 3134, 2467, 2599, 3711, 1667, 3365, 2944, 1896, 1179, 2198,\n",
       "          3292,  353, 3891,  528]),\n",
       "  tensor([1814, 3533,  235, 1663, 2190, 2542, 2558, 1157, 3571, 3476,  605,  588,\n",
       "           867, 1400, 3264, 2098]),\n",
       "  tensor([3147, 1832,  925, 2544,  553, 1962, 2026,  517, 1982, 1602, 2407, 2340,\n",
       "          3454, 1491,  754,  185]),\n",
       "  tensor([ 288, 3220, 3688, 1970, 2200, 3739, 3995, 2053, 3819, 2299, 1421, 1156,\n",
       "          1516, 1855, 3003,  726]),\n",
       "  tensor([1140,  580, 2449, 3772,  595, 2655, 3678,    8, 2976,  990, 1575,  513,\n",
       "          1953, 3309, 3805, 2891]),\n",
       "  tensor([ 449, 2306, 1589, 2787, 2365, 2415, 2412,   20, 3699, 3945, 2192, 2037,\n",
       "          3704,  933, 2920, 3359]),\n",
       "  tensor([1781, 1019, 2245, 2942, 1255, 1456, 1442,   68, 2493, 3478,  563, 4037,\n",
       "          2516, 3718, 3475, 1136]),\n",
       "  tensor([3014, 4062,  776, 3563,  911, 1714, 1658,  259, 1768, 1611, 2237, 3848,\n",
       "          1857, 2569, 1600,  433]),\n",
       "  tensor([3850, 3946, 3089, 1950, 3630, 2748, 2523, 1024, 2963, 2336,  743, 3091,\n",
       "          3320, 2070, 2290, 1720]),\n",
       "  tensor([3100, 3482,   56, 3691, 2217, 2785, 1886, 4084, 3645, 1139, 2958,   64,\n",
       "           980,   76,  955, 2772]),\n",
       "  tensor([ 100, 1627,  212, 2464,  662, 2933, 3434, 4034, 2277,  446, 3626,  243,\n",
       "          3906,  292, 3805, 2881]),\n",
       "  tensor([ 387, 2398,  833, 1651, 2633, 3528, 1435, 3836,  901, 1772, 2204,  958,\n",
       "          3321, 1153, 2920, 3319]),\n",
       "  tensor([1535, 1387, 3317, 2494, 2325, 1809, 1631, 3044, 3590, 2980,  610, 3819,\n",
       "           982,  501, 3473,  974]),\n",
       "  tensor([2029, 1439,  967, 1772, 1096, 3126, 2414, 3972, 2060, 3713, 2425, 2974,\n",
       "          3915, 1992, 1592, 3881]),\n",
       "  tensor([4008, 1646, 3853, 2977,  274,  204, 1451, 3585,   35, 2550, 1493, 3692,\n",
       "          3359, 3858, 2258, 3223]),\n",
       "  tensor([3730, 2476, 3109, 3701, 1084,  804, 1696, 2039,  125, 1993, 1862, 2465,\n",
       "          1133, 3130,  828,  589]),\n",
       "  tensor([2618, 1697,  136, 2501,  228, 3201, 2673, 4048,  487, 3862, 3337, 1656,\n",
       "           423,  220, 3300, 2343]),\n",
       "  tensor([2266, 2679,  531, 1799,  897,  504, 2487, 3892, 1933, 3145, 1047, 2513,\n",
       "          1678,  866,  900, 1165]),\n",
       "  tensor([ 857, 2509, 2109, 3088, 3576, 2001, 1742, 3266, 3621,  278,   80, 1848,\n",
       "          2603, 3452, 3586,  549]),\n",
       "  tensor([3413, 1831,  231,   49, 2004, 3895, 2860,  763, 2181, 1098,  306, 3281,\n",
       "          2205, 1505, 2044, 2184]),\n",
       "  tensor([1350, 3214,  912,  182, 3908, 3280, 3235, 3040,  518,  284, 1209,  823,\n",
       "           614, 1911, 4066,  531]),\n",
       "  tensor([1290,  553, 3635,  716, 3329,  817,  638, 3954, 2059, 1121,  725, 3280,\n",
       "          2441, 3534, 3962, 2112]),\n",
       "  tensor([1049, 2198, 2237, 2851, 1013, 3256, 2540, 3515,   31,  375, 2885,  817,\n",
       "          1559, 1834, 3548,  241]),\n",
       "  tensor([  88,  585,  743, 3197, 4039,  724, 1956, 1758,  112, 1488, 3333, 3254,\n",
       "          2125, 3228, 1892,  951]),\n",
       "  tensor([ 338, 2326, 2957,  486, 3856, 2881, 3713, 2923,  433, 1841, 1031,  715,\n",
       "           293,  609, 3460, 3791]),\n",
       "  tensor([1337, 1097, 3623, 1932, 3122, 3320, 2552, 3487, 1719, 3254,   13, 2846,\n",
       "          1159, 2422, 1537, 2861]),\n",
       "  tensor([1238,  280, 2191, 3617,  187,  978, 2003, 1647, 2765,  716,   38, 3178,\n",
       "           525, 1481, 2038, 3237]),\n",
       "  tensor([ 842, 1105,  560, 2166,  734, 3897, 3904, 2480, 2854, 2851,  137,  411,\n",
       "          2087, 1813, 4043,  645]),\n",
       "  tensor([3354,  309, 2227,  458, 2923, 3287, 3313, 1715, 3211, 3198,  533, 1631,\n",
       "           144, 3141, 3872, 2567]),\n",
       "  tensor([1114, 1223,  701, 1818, 3487,  846,  951, 2750,  543,  489, 2117, 2415,\n",
       "           561,  263, 3186, 2063]),\n",
       "  tensor([ 348,  784, 2791, 3161, 1645, 3372, 3789, 2793, 2160, 1944,  261, 1455,\n",
       "          2232, 1038,  442,   45]),\n",
       "  tensor([1378, 3124, 2957,  344, 2472, 1186, 2856, 2965,  433, 3665, 1031, 1712,\n",
       "           723,   41, 1754,  167]),\n",
       "  tensor([1404,  196, 3623, 1361, 1681,  633, 3220, 3655, 1720, 2357,   13, 2737,\n",
       "          2878,  150, 2907,  654]),\n",
       "  tensor([1506,  770, 2191, 1334, 2613, 2518,  579, 2319, 2769, 1222,   39, 2742,\n",
       "          3305,  586, 3421, 2604]),\n",
       "  tensor([1916, 3067,  560, 1227, 2248, 1866, 2303, 1072, 2870,  778,  144, 2763,\n",
       "           918, 2332, 1381, 2212]),\n",
       "  tensor([3554, 4063, 2228,  797,  787, 3356, 1007,  180, 3273, 3097,  563, 2845,\n",
       "          3658, 1122, 1416,  644]),\n",
       "  tensor([1916, 3949,  707, 3174, 3134, 1123, 4013,  706,  791,   87, 2238, 3174,\n",
       "          2330,  378, 1553, 2564]),\n",
       "  tensor([3554, 3496, 2815,  394,  234,  383, 3752, 2810, 3149,  333,  745,  395,\n",
       "          1113, 1499, 2104, 2050]),\n",
       "  tensor([1914, 1683, 3053, 1563,  921, 1517, 2707, 3033,  295, 1320, 2966, 1566,\n",
       "           341, 1886,  210, 4090]),\n",
       "  tensor([3548, 2621, 4005, 2143, 3669, 1957, 2621, 3925, 1166, 1169, 3657, 2155,\n",
       "          1350, 3435,  827, 4060]),\n",
       "  tensor([1889, 2279, 3718,  367, 2375, 3717, 2278, 3398,  554,  568, 2327,  414,\n",
       "          1289, 1439, 3296, 3937]),\n",
       "  tensor([3446,  909, 2569, 1456, 1295, 2566,  907, 1289, 2203, 2257, 1101, 1643,\n",
       "          1048, 1647,  881, 3448]),\n",
       "  tensor([1484, 3622, 2071, 1714, 1072, 2060, 3615, 1046,  605,  821,  294, 2461,\n",
       "            81, 2477, 3509, 1489]),\n",
       "  tensor([1826, 2185,   78, 2746,  180,   33, 2158,   76, 2405, 3270, 1164, 1637,\n",
       "           311, 1701, 1735, 1845]),\n",
       "  tensor([3195,  534,  297, 2779,  706,  118,  427,  289, 1416,  778,  547, 2439,\n",
       "          1231, 2696, 2832, 3271]),\n",
       "  tensor([ 480, 2122, 1173, 2912, 2811,  457, 1694, 1142, 1553, 3097, 2175, 1552,\n",
       "           814, 2580, 3122,  784]),\n",
       "  tensor([1906,  281,  583, 3441, 3037, 1814, 2666,  460, 2101,   86,  493, 2098,\n",
       "          3243, 2116,  188, 3121]),\n",
       "  tensor([3514, 1109, 2318, 1462, 3942, 3146, 2459, 1825,  197,  329, 1959,  187,\n",
       "           669,  259,  740,  182]),\n",
       "  tensor([1754,  326, 1067, 1740, 3467,  283, 1632, 3192,  774, 1301, 3725,  736,\n",
       "          2663, 1023, 2945,  716]),\n",
       "  tensor([2905, 1289,  157, 2851, 1567, 1118, 2419,  465, 3083, 1094, 2598, 2929,\n",
       "          2447, 4079, 3574, 2849]),\n",
       "  tensor([3414, 1046,  615, 3198, 2159,  361, 1470, 1846,   31,  268, 2185, 3509,\n",
       "          1581, 4014, 1994, 3190]),\n",
       "  tensor([1354,   73, 2447,  490,  432, 1430, 1771, 3276,  112, 1058,  533, 1736,\n",
       "          2214, 3755, 3866,  458]),\n",
       "  tensor([1308,  277, 1583, 1947, 1713, 1610, 2974,  802,  436,  123, 2117, 2835,\n",
       "           651, 2719, 3164, 1818]),\n",
       "  tensor([1122, 1094, 2223, 3678, 2741, 2330, 3691, 3194, 1730,  478,  261, 3133,\n",
       "          2591, 2669,  355, 3163]),\n",
       "  tensor([ 378,  268,  687, 2411, 2758, 1113, 2464,  475, 2810, 1898, 1029,  229,\n",
       "          2158, 2469, 1407,  350]),\n",
       "  tensor([1500, 1059, 2734, 1440, 2826,  344, 1651, 1886, 3034, 3481,    7,  903,\n",
       "           427, 1669, 1519, 1387]),\n",
       "  tensor([1892,  127, 2731, 1650, 3100, 1362, 2494, 3434, 3931, 1622,   15, 3599,\n",
       "          1695, 2568, 1965, 1439]),\n",
       "  tensor([3458,  494, 2717, 2492,  100, 1337, 1770, 1435, 3422, 2377,   47, 2095,\n",
       "          2671, 2066, 3750, 1648]),\n",
       "  tensor([1532, 1962, 2663, 1763,  388, 1238, 2970, 1632, 1388, 1304,  174,  174,\n",
       "          2480,   57, 2700, 2481]),\n",
       "  tensor([2018, 3737, 2445, 2944, 1539,  841, 3675, 2418, 1443, 1106,  684,  683,\n",
       "          1713,  214, 2596, 1718]),\n",
       "  tensor([3964, 2645, 1575, 3572, 2045, 3350, 2398, 1466, 1661,  316, 2722, 2719,\n",
       "          2744,  843, 2178, 2763]),\n",
       "  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])],\n",
       " 'token_type_ids': [tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(batch, dict)\n",
    "for t in batch.values():\n",
    "    print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "batch.keys()\n",
    "for k, v in batch.items():\n",
    "    if type(v) == list:\n",
    "        print(k + \": \" + str(len(v)))\n",
    "    else:\n",
    "        print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['species_name', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/.conda/envs/m2_bert/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for eli5_category contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/eli5_category\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "eli5 = load_dataset(\"eli5_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '5lchat',\n",
       " 'title': \"Why there was a 'leap second' added to the end of 2016?\",\n",
       " 'selftext': '',\n",
       " 'category': 'Other',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dbuoyxl', 'dbur7gi', 'dbuotht'],\n",
       "  'text': ['the rotation of the earth is not a constant. in fact the rotation of the earth is slowing down, which means that a full day is getting slightly longer. without leap seconds our clocks would slowly drift ever so slightly out of sync with the actual day. we could deal with this by redefining how how long 1 second is, making it slightly longer so that one day is still exactly 24*60*60 seconds. but in practice that is really inconvenient for a lot of our technology which relies on very precise timing. its easier to just move us ahead one second every couple of years or so.',\n",
       "   \"The Earth's rotation is not regular. It varies a bit, so sometimes we add a second. We do this to ensure that noon is always going to be sometime around mid-day. If we did not add leap seconds, over a very long period of time where the Earth's rotation slowly changed, noon could end up being at dusk. We want to keep 7am in the morning, noon at mid-day, 7pm around evening, etc. Though we have never had one, it's also possible to have a negative leap second. That is, taking away a second from the year. This has never happened, but if the Earth's rotation were to speed up, it could happen. The biggest thing to know about leap seconds is that they can cause computer problems. You might remember the Y2K bug. A leap second can cause similar problems, and they actually have caused problems in the past. The reason for this is that generally we expect a day to have 24 hours, and for time to always move forward. With a leap second this is not true. When writing software, programers try to think of all the possible exceptions that could happen withing their code. For example, the program might expect a word, but instead get a number. A good programmer will check for these exceptions and deal with them. However, a programer can easily forget about leap seconds and not have a fail-safe in their code for when a day have more than 24 hours. When such an exception happens, the program can produce errors or crash. It is an interesting topic, you can read more about it here: URL_0\",\n",
       "   \"Because the Earth's rotation is slowing. If you multiply 24 hours by 60 minutes by 60 seconds, you find that there are 86400 seconds per day. The problem is that our definition of the second is based on [an average that is a century old.]( URL_0 ) In modern times, the average day is about 2 thousandths of a second longer—again, because of Earth's slowing rotation. Those thousandths of a second add up, so every few years we have to slip in an extra second to account for them. Without leap seconds, we'd eventually end up with noon at 7 o'clock, though admittedly, this would take a very long time.\"],\n",
       "  'score': [44, 5, 4],\n",
       "  'text_urls': [[],\n",
       "   ['http://adminhacks.com/leap-second-bugs.html'],\n",
       "   ['https://en.wikipedia.org/wiki/Newcomb%27s_Tables_of_the_Sun']]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/91772 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):   1%|          | 1000/91772 [00:00<01:15, 1206.20 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 91772/91772 [00:21<00:00, 4229.03 examples/s]\n",
      "Map (num_proc=4):   0%|          | 0/5446 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  18%|█▊        | 1000/5446 [00:01<00:05, 859.05 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  43%|████▎     | 2361/5446 [00:01<00:01, 1815.09 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 5446/5446 [00:02<00:00, 2410.42 examples/s]\n",
      "Map (num_proc=4):   0%|          | 0/2375 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  25%|██▍       | 593/2375 [00:00<00:01, 943.55 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 2375/2375 [00:00<00:00, 2964.87 examples/s]\n",
      "Map (num_proc=4):   0%|          | 0/5411 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  18%|█▊        | 1000/5411 [00:00<00:03, 1195.94 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 5411/5411 [00:01<00:00, 3394.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "eli5 = eli5.flatten()\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])\n",
    "tokenized_eli6 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched = True,\n",
    "    num_proc = 4,\n",
    "    remove_columns = eli5[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate sequences\n",
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "\n",
    "    # Concatenate all texts.\n",
    "\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "\n",
    "    # customize this part to your needs.\n",
    "\n",
    "    if total_length >= block_size:\n",
    "\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "\n",
    "    # Split by chunks of block_size.\n",
    "\n",
    "    result = {\n",
    "\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "\n",
    "        for k, t in concatenated_examples.items()\n",
    "\n",
    "    }\n",
    "\n",
    "    return result\n",
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "\n",
    "collate_fn = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "input_ids\n",
      "torch.Size([16, 128])\n",
      "attention_mask\n",
      "torch.Size([16, 128])\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(lm_dataset[\"train\"], batch_size=16, collate_fn=collate_fn)\n",
    "iterable = iter(loader)\n",
    "batch = next(iterable)\n",
    "for k, v in batch.items():\n",
    "    print(v.shape)\n",
    "    print(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "input_ids\n",
      "128\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "for k, v in lm_dataset[\"train\"][0].items():\n",
    "    print(len(v))\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from composer import Trainer\n",
    "from composer.models import ComposerClassifier\n",
    "from composer.algorithms import LabelSmoothing, CutMix, ChannelsLast\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Toy convolutional neural network architecture in pytorch for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3, 3), padding=0)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 16, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.adaptive_avg_pool2d(out, (4, 4))\n",
    "        out = torch.flatten(out, 1, -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/.conda/envs/m2_bert/lib/python3.10/site-packages/composer/trainer/trainer.py:968: UserWarning: No optimizer was specified. Defaulting to DecoupledSGDW(lr=0.1)\n",
      "  warnings.warn(('No optimizer was specified. Defaulting to '\n",
      "******************************\n",
      "Config:\n",
      "enabled_algorithms/ChannelsLast: true\n",
      "enabled_algorithms/CutMix: true\n",
      "enabled_algorithms/LabelSmoothing: true\n",
      "node_name: unknown because NODENAME environment variable not set\n",
      "num_cpus_per_node: 1\n",
      "num_nodes: 1\n",
      "rank_zero_seed: 4240981184\n",
      "\n",
      "******************************\n",
      "train          Epoch   0:    0%|| 0/14426 [00:00<?, ?ba/s]         "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mComposerClassifier(module\u001b[38;5;241m=\u001b[39mModel(), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m      4\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/composer/trainer/trainer.py:1766\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_dataloader, train_dataloader_label, train_subset_num_batches, duration, reset_time, schedulers, scale_schedule_ratio, step_schedulers_every_batch, eval_dataloader, eval_subset_num_batches, eval_interval, device_train_microbatch_size, precision)\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m ClosureGradScaler() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_closures() \u001b[38;5;28;01melse\u001b[39;00m GradScaler()\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_batch_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1766\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/composer/trainer/trainer.py:1919\u001b[0m, in \u001b[0;36mTrainer._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mbatch_to_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_data_spec\u001b[38;5;241m.\u001b[39mdevice_transforms(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m-> 1919\u001b[0m rank_num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_data_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_samples_in_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m rank_num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_data_spec\u001b[38;5;241m.\u001b[39mget_num_tokens_in_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed_enabled:\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/composer/core/data_spec.py:252\u001b[0m, in \u001b[0;36mDataSpec._default_get_num_samples_in_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    250\u001b[0m             dim0_sizes\u001b[38;5;241m.\u001b[39mappend(t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 252\u001b[0m     dim0_sizes \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(dim0_sizes)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dim0_sizes[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/m2_bert/lib/python3.10/site-packages/composer/core/data_spec.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m             dim0_sizes\u001b[38;5;241m.\u001b[39mappend(t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 252\u001b[0m     dim0_sizes \u001b[38;5;241m=\u001b[39m [\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(dim0_sizes)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dim0_sizes[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainer = Trainer(\n",
    "    model=ComposerClassifier(module=Model(), num_classes=10),\n",
    "    train_dataloader=loader,\n",
    "    max_duration=\"2ep\",\n",
    "    algorithms=[\n",
    "        LabelSmoothing(smoothing=0.1),\n",
    "        CutMix(alpha=1.0),\n",
    "        ChannelsLast(),\n",
    "    ],\n",
    ")\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
